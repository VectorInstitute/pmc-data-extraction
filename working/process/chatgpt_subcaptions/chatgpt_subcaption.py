# -*- coding: utf-8 -*-
"""ChatGPT_SubCaption.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1miGiK-AOVHXFLH3_IyHH0aeKHBF3la_h
"""

import argparse
import json
# import tiktoken
import os
import random
import re
import traceback
from pathlib import Path

import openai
# import ipdb
import pandas as pd
from datasets import concatenate_datasets, load_dataset
from tqdm import tqdm

api_pool = [
  '...'
]

if __name__ == "__main__":
  parser = argparse.ArgumentParser()
  parser.add_argument('--split', default=8, type=int)
  parser.add_argument('--part', default=0, type=int)
  parser.add_argument('--log_interval', default=100, type=int)
  parser.add_argument('--unprocessed_data_path', default=None, type=str)
  parser.add_argument('--processed_data_path', default=None, type=str)
  args = parser.parse_args()
  
  openai.api_key = random.choice(api_pool)
  template = \
  """
  Subfigure labels are letters referring to individual subfigures within a larger figure. 
  This is a caption:"%s" 
  Check if the caption contains explicit subfigure label. 
  If not, output "No." and end the generation. 
  If yes, output "Yes", then generate the subcaption of the subfigures according to the caption. 
  The output should use the template: Yes.\n Subfigure-A: ... \n Subfigure-B: ... \n ......
  The label should be removed from subcaption.
  """

  with open(args.unprocessed_data_path, 'r') as f:
    lines = f.readlines()
    dataset = [json.loads(line) for line in lines]

  # 分配任务
  part = args.part
  length = int(len(dataset)/args.split)+1
  log_interval = args.log_interval  # 每处理N个记录一次
  save_path = '/content/drive/MyDrive/zzh_files/subcaps_v0_split%d/result_%d.jsonl'%(args.split, part)

  # 读取已经处理一部分的结果，避免重复
  processed_data_path = args.processed_data_path if args.processed_data_path else save_path
  processed_data = []
  if Path(processed_data_path).exists():
    with open(processed_data_path, 'r') as f:
      lines = f.readlines()
      processed_data = [json.loads(line) for line in lines]
  processed_id = []
  yes_count = 0
  no_count = 0
  unformatted = 0
  for datum in processed_data:
    processed_id.append(datum['comfig_id'])
    if datum['status'] == 'Separable':
      yes_count += 1
    elif datum['status'] == 'UnSeparable':
      no_count += 1
    elif datum['status'] == 'Unformatted':
      unformatted += 1

  processed_queue = []  # 还没保存的结果
  found_start = False
  for idx in tqdm(range(part*length, min((part+1)*length, len(dataset)))):
  # for idx in tqdm(range(0, 1)): # To debug
    if len(processed_queue) >= log_interval:
      # 保存
      with open(save_path, 'a') as f:
        for datum in processed_queue:
          f.write(json.dumps(datum)+'\n')
      processed_queue = []
      print('Log : %d processed, %d success, %d unseparable, %d unformatted'%(len(processed_id), yes_count, no_count, unformatted))

    sample = dataset[idx]
    comfig_id = sample['comfig_id']
    if (not found_start) and (comfig_id in processed_id):
      continue
    else:
      found_start = True
      
    caption = sample['caption']
    # caption = 'No caption is found here.' # To debug
    message = template % caption
    message = [{"role": "system", "content": 'You are a helpful assistant.'},
              {"role": "user", "content": message}]
    
    # 如果request没有相应，持续重复
    while (1):
      try:
        response = openai.ChatCompletion.create(
                              model="gpt-3.5-turbo",
                              messages=message
                            )
        break
      except:
        tb_info = traceback.format_exc()
        if 'You exceeded your current quota' in tb_info:
          openai.api_key = random.choice(api_pool)
        print('Retry')

    response = response["choices"][0]['message']["content"]
    generate_time = 0
    # 多次生成得到规定格式
    while ('Yes.' not in response) and ('No.' not in response) and (generate_time < 5):
      generate_time += 1
      while (1):
        try:
          response = openai.ChatCompletion.create(
                              model="gpt-3.5-turbo",
                              messages=message
                            )
          break
        except:
          tb_info = traceback.format_exc()
          if 'You exceeded your current quota' in tb_info:
            openai.api_key = random.choice(api_pool)
          print('Retry')
      response = response["choices"][0]['message']["content"]
    # 判断
    if 'Yes.' not in response:
      if 'No.' in response:
        # 不可分
        no_count += 1
        # del sample['url_name']
        sample['status'] = 'UnSeparable'
        # sample['comfig_id'] = comfig_id
        processed_queue.append(sample)
        processed_id.append(comfig_id)
        continue
      else:
        # 有限次数内没有生成规定格式
        unformatted += 1
        # del sample['url_name']
        sample['status'] = 'Unformatted'
        # sample['comfig_id'] = comfig_id
        processed_queue.append(sample)
        processed_id.append(comfig_id)
        continue
    else:
      # 可分
      subcap_dict = {}
      pattern = re.compile(r'Subfigure-[a-zA-Z]:.+')
      matches = pattern.findall(response)
      for subcap in matches:
        label = subcap[10]  # a-z or A-Z
        content = subcap[12:-1]
        subcap_dict[label] = content
      if len(subcap_dict) == 0:
        unformatted += 1
        # del sample['url_name']
        sample['status'] = 'Unformatted'
        # sample['comfig_id'] = comfig_id
      else:
        yes_count += 1
        # del sample['url_name']
        sample['subcaptions'] = subcap_dict
        sample['status'] = 'Separable'
        # sample['comfig_id'] = comfig_id
      processed_queue.append(sample)
      processed_id.append(comfig_id)

  # 保存
  with open(save_path, 'a') as f:
    for datum in processed_queue:
      f.write(json.dumps(datum)+'\n')
  processed_queue = []
  print('Log : %d processed, %d success, %d unseparable, %d unformatted'%(len(processed_id), yes_count, no_count, unformatted))


